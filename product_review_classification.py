import re
import json
import pandas as pd

from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.naive_bayes import MultinomialNB 

from sklearn.metrics import accuracy_score, f1_score
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import confusion_matrix, classification_report

import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix

import matplotlib.pyplot as plt
import plotly.graph_objs as go
from plotly.offline import iplot

# Cargar datos
data = pd.read_csv("/content/reviews_vidjew_es.csv")
data.head()

train, test = train_test_split(data, test_size=0.3)

print(f"Tenemos {data.shape[0]} datos en total")
print(f"El conjunto de datos de entrenamiento (train) tiene: {train.shape[0]} datos.")
print(f"El conjunto de datos de prueba (test) tiene {test.shape[0]} datos.")

import nltk
nltk.download('stopwords')

stopwords_sp = stopwords.words('spanish')

def pre_procesado(texto):
    texto = texto.lower()
    texto = re.sub(r"[\W\d_]+", " ", texto)
    texto = texto.split() # Tokenizar
    texto = [palabra for palabra in texto if palabra not in stopwords_sp]
    texto = " ".join(texto)
    return texto
  
tfidf_vect = TfidfVectorizer(preprocessor=pre_procesado)

X_train = tfidf_vect.fit_transform(train.review_body.values)
y_train = train.product_category.values

X_test = tfidf_vect.transform(test.review_body.values)
y_test = test.product_category.values

print(f"Tama単o de X_train (entrenamiento): {pd.DataFrame(X_train.toarray()).shape}")
print(f"Tama単o de X_test (prueba): {pd.DataFrame(X_test.toarray()).shape}")
print(f"Tama単o de y_train {len(y_train)} y tama単o de y_test {len(y_test)}")

nb = MultinomialNB()
nb.fit(X_train, y_train)

y_pred_nb = nb.predict(X_test)

metricas = [precision_score, recall_score, f1_score]

for metrica in metricas:
    print(metrica.__name__)
    print(f"{metrica(y_test, y_pred_nb, pos_label='video_games'):.2f}")

print(f"{accuracy_score(y_test, y_pred_nb):>15.2f}")

print(classification_report(y_test, y_pred_nb))
print()

confusion_matrix(y_test, y_pred_nb)
fig = plt.figure(figsize=(10,10))

plot_confusion_matrix(nb, X_test, y_test, cmap="Blues", normalize='true').im_.colorbar.remove()
plt.title("Naive Bayes")

vocab = {value:key for key,value in tfidf_vect.vocabulary_.items()}
vocab

[(vocab[e[0]], round(e[1],2)) for e in zip(nb.coef_[0].argsort(), sorted(nb.coef_[0]))][:10]

[(vocab[e[0]], round(e[1],2)) for e in zip(nb.coef_[0].argsort(), sorted(nb.coef_[0]))][-10:]

